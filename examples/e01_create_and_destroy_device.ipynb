{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create and Destroy Device\n",
    "\n",
    "__Device creation, vector operation and torch interop, destroying device__\n",
    "\n",
    "Vulky is a python facade to vulkan with reduced and simpler interface focused primarly to academic purposes. Objects are designed to represent graphics pipelines and techniques in a more compact way."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce5983b7bb1a17bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "try: # install all dependencies in colab \n",
    "    import google.colab\n",
    "    !sudo apt-get update -y\n",
    "    !sudo apt-get install -y libnvidia-gl-555 vulkan-tools glslang-tools vulkan-validationlayers-dev\n",
    "    !pip install pyav==13.1.0\n",
    "    !pip install git+https://github.com/rendervous/vulky_project.git\n",
    "except:\n",
    "    print(\"Executing locally\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b9edf834b3a2e4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start importing the module ```vulky```\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "237dae07093fb7c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import vulky as vk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c771f637121d64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectors and Matrices\n",
    "\n",
    "Apart from rendering, **Vulky** provides object types for working with vectors and matrices, internally wrapping PyTorch tensors. This makes it easier to interpret tensors as 3D geometric entities while preserving differentiability whenever possible. These types also serve as representations of equivalent Vulkan shader types (e.g., `vec2`, ..., `vec4`; `mat2`, ..., `mat4x3`, `mat4`).\n",
    "\n",
    "A key distinction is that, in **Vulky**, matrices are **row-major**, matching the memory layout of PyTorch tensors. Additionally, all transformations assume **row vectors**, which aligns with the typical shape of a batch of vectors in PyTorch (`B × D`)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a29d4443ab4d60ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "x = vk.vec3(1., 0., .0)\n",
    "M = vk.mat3.rotation(vk.vec3(0., 0.0, 1.0), 3.14159/2)\n",
    "y = x @ M  # proper way to transform a vertex in vulky\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "neg_y = M @ x  # also works because a special treatment of 1D tensors in PyTorch as column vectors. But has the transposed effect.\n",
    "print(neg_y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1209b4f0bb295e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vector and matrix types in **Vulky** also support batching. For instance, if you want to refer to a bidirectional array of shape `(16, 16)` containing `vec4` elements, you can use:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8898e45cfdb30277"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = vk.vec4.zero(16, 16)\n",
    "print(t)\n",
    "print(t.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3da100f36dce6da4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Operations involving multiple vectors and matrices will automatically **broadcast** to match the largest batch shape, following PyTorch-style broadcasting rules."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc71de703f6627c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t += vk.vec4(1.0, 0.2, 0.3, 0.4)\n",
    "print(t)\n",
    "print(t.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77ce270dbb6a87d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "An important observation is that indexing into vectors and matrices refers to their **components**, not to individual **batch instances**.  \n",
    "For example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b295fc9e70410122"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t[0] = 1.0  # first component of all (16,16) vec4 where set to 1.0\n",
    "t.y = 2.0  # equivalent to index, a named access to the field is also valid and refers to whole the batch\n",
    "print(t)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f74c359d7098f54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Devices ##\n",
    "\n",
    "For graphics, **Vulky** internally operates with a single Vulkan instance at a time but can manage multiple devices. The concept of an *active device* is central: most methods in the Vulky library implicitly refer to this active device.\n",
    "\n",
    "You can set the active device using the `device_manager` method by passing the desired device object. By default, the device created most recently becomes the active one.\n",
    "\n",
    "If you don't plan to switch between devices later, it's not necessary to store a reference to the device — Vulky will continue to use the active one by default."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ae4b87fad8e133a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vk.create_device(debug=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ada4dddfdd5739d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vulky automatically manages two types of memory: memory accessible by the host (CPU) and memory local to the graphics device (GPU). \n",
    "\n",
    "When CUDA is available, the device memory is exported to CUDA and the PyTorch library, allowing for seamless creation of tensors that are backed by Vulkan-managed memory. This simplifies interoperability between Vulkan and PyTorch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b039c0c80c25dc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = vk.tensor(2,4)\n",
    "print(t + 0.2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51570ac9f30ddd79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that those tensors are created in gpu memory. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4353878a3d4c0929"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(t.device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171725f807abf90e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also, for the vector types the library provides different random generators based on torch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d4432e9177d16cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = vk.vec3.rand()  # U[0..1)\n",
    "b = vk.vec3.randn()  # N(0, I)\n",
    "c = vk.vec3.randd(1000)  # Uniform in hypersphere"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "476c2a6fdd035fd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(3,3), dpi=200)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(c.x, c.y, c.z)\n",
    "ax.axis('off')\n",
    "ax.set_box_aspect((1,1,1))\n",
    "fig.tight_layout(pad=0.0)\n",
    "fig.savefig('teaser1.jpg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3edd376fd2567577"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although **Vulky** tensors can be used like regular `torch` tensors, the memory is owned and managed by Vulky. As a result, these tensors **must be explicitly deleted** before the associated Vulkan device is destroyed to avoid memory issues or crashes.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c28aa0ccc7a8a471"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del t\n",
    "vk.quit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f66b76d5879cf59"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the rest of the notebooks we won't close explicitly the device, although it is automatically performed at exit, it is unpleasant when we want to repeat cell executions and the device is already destroyed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e6e0a7779680dc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
