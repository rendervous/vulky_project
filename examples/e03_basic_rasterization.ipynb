{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basic Rasterization\n",
    "\n",
    "__framebuffers, dispatching primitives, instances__ \n",
    "\n",
    "A distinctive aspect of a rasterizer is the way output is handled. In a compute shader, generated image is accessed in random positions to store the output value. In a rasterizer, it is convenient that multiple targets and depth-stencil buffers are aligned and there is an implicit process consuming colors, depth, and stencil values, operating with them and then updating the respective buffers. The attached images for colors can be set in the fragment shader using out locations, while the depth-stencil operation can be statically defined in the pipeline or dynamically in the command buffer manager.\n",
    "\n",
    "In this tutorial we will render different quads showing the setup of graphics pipelines and how instances works."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "291187c2f3a6e815"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import vulky as vk\n",
    "import torch\n",
    "\n",
    "vk.create_device(debug=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6becb17d41d811b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, some constants to parameterize the example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abe5a6461b86bb88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SCREEN_WIDTH = 512\n",
    "SCREEN_HEIGHT = 512\n",
    "NUMBER_OF_SPRITES = 30"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27d1ad42ec9cd452"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create the images for render target and depth buffer. They will have the same dimension. Automatically vulky will use the format for depth-stencil buffer with better definition."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "927bb67386f0944f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "render_target = vk.render_target(\n",
    "    image_format=vk.Format.VEC4,\n",
    "    width=SCREEN_WIDTH,\n",
    "    height=SCREEN_HEIGHT\n",
    ")\n",
    "\n",
    "depth_buffer = vk.depth_stencil(\n",
    "    width=SCREEN_WIDTH,\n",
    "    height=SCREEN_HEIGHT\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba29f41e46ac65f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will define a buffer with the properties for the sprites, one for each instance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fd7a1b643f0241d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sprite_properties = vk.structured_buffer(\n",
    "    count=NUMBER_OF_SPRITES,\n",
    "    element_description=dict(\n",
    "        offset=vk.vec3,\n",
    "        size=float,\n",
    "        color=vk.vec4,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72b465a1ef74f127"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's populate randomly. They will represent boxes in the screen, the offset z will be used for depth and the color"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c67ed7c3ac89e9c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with sprite_properties.map(mode='in', clear=True) as b:\n",
    "    b.offset = torch.rand(NUMBER_OF_SPRITES, 3)*2 - 1.0\n",
    "    b.offset.z *= 0.5\n",
    "    b.offset.z += 0.5\n",
    "    b.size = torch.randn(NUMBER_OF_SPRITES, 1)*0.05\n",
    "    b.color = vk.vec4(0.5, 0.5, 0.5, 0.5) + torch.randn(NUMBER_OF_SPRITES, 4)*0.1\n",
    "    # b.color is a vec4, b.color[0] is not the first color but the first component for all colors\n",
    "    b.color[0] = 1.0  # set the red component for all 30 colors to 1.\n",
    "    # but cast to torch.Tensor is possible, meaning that is valid\n",
    "    b.color.as_subclass(torch.Tensor)[:NUMBER_OF_SPRITES//2, 3] = 1.0  \n",
    "    # That makes all alpha components for the first 15 colors 1.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b38587f02ad2407e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mapped buffers can be accessed by the fields. The set access to the field will copy a tensor or constant to the field for all elements in the buffer. Notice that if the element is a vector or a matrix, the indexing will behave differently. Next, let's define the vertex and fragment shader code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "776c139ff56bd864"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vertex_shader_code = \"\"\"\n",
    "#version 450\n",
    "#extension GL_EXT_scalar_block_layout: enable\n",
    "\n",
    "layout(location = 0) out vec4 out_color;\n",
    "\n",
    "struct SpriteInfo\n",
    "{\n",
    "    vec3 offset;\n",
    "    float size;\n",
    "    vec4 color;\n",
    "};\n",
    "\n",
    "layout(scalar, set=0, binding=0) buffer SpriteInfos {\n",
    "    SpriteInfo[] data;\n",
    "} infos;\n",
    "\n",
    "vec2[] quad = {\n",
    "    vec2(-1.0, -1.0), \n",
    "    vec2(1.0, -1.0),\n",
    "    vec2(-1.0, 1.0),\n",
    "    vec2(-1.0, 1.0),\n",
    "    vec2(1.0, -1.0),\n",
    "    vec2(1.0, 1.0)\n",
    "};\n",
    "\n",
    "void main()\n",
    "{\n",
    "    SpriteInfo info = infos.data[gl_InstanceIndex];\n",
    "    vec4 P = vec4(vec3(quad[gl_VertexIndex], 0)*info.size + info.offset, 1.0);\n",
    "    gl_Position = P;\n",
    "    out_color = info.color;\n",
    "}\n",
    "\"\"\"\n",
    "fragment_shader_code = \"\"\"\n",
    "#version 450\n",
    "layout(location = 0) in vec4 in_color;\n",
    "layout(location = 0) out vec4 out_color;\n",
    "void main()\n",
    "{\n",
    "    out_color = in_color;\n",
    "}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcbc33b0f4101a83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that the vertex shader will operate on ```gl_VertexIndex``` and ```gl_InstanceIndex``` builtins. Now, let's define the pipeline object that will relate shaders, the resources bindings and the targets of the framebuffer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d45d91d10126f88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = vk.pipeline_graphics()\n",
    "pipeline.attach(0, render_target=vk.Format.VEC4)\n",
    "pipeline.attach(1, depth_buffer=vk.Format.DEPTH_STENCIL)\n",
    "pipeline.layout(set=0, binding=0, sprite_properties=vk.DescriptorType.STORAGE_BUFFER)\n",
    "with pipeline.shader_stages(vk.ShaderStage.VERTEX):\n",
    "    pipeline.load_shader_from_source(vertex_shader_code)\n",
    "with pipeline.shader_stages(vk.ShaderStage.FRAGMENT):\n",
    "    pipeline.load_shader_from_source(fragment_shader_code)\n",
    "pipeline.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b8bd72abaef031"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the pipeline is closed, the layout is defined, and derived objects can be created, framebuffers and descriptor set collections. The framebuffer object defines the images that are bound to the pipeline before execution. In vulkan, a render pass (involving a framebuffer) can define subpasses to optimize for dependencies between targets. In vulky, it is simplified to a single subpass.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "908c6746241255b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "framebuffer = pipeline.create_framebuffer(\n",
    "    width=SCREEN_WIDTH,\n",
    "    height=SCREEN_HEIGHT,\n",
    "    render_target=render_target,\n",
    "    depth_buffer=depth_buffer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ef33ec20edb6b33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pipeline is also used to create the descriptor set, in this example to bind a buffer with all sprite properties."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bca56d3cde31352"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global_bindings = pipeline.create_descriptor_set_collection(set=0, count=1)\n",
    "global_bindings[0].update(sprite_properties=sprite_properties)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a77da1fb735ce54f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will populate a command buffer. As an example, we will record the commands with a manager and freeze it before submitting. This is the way vulky allows to re-submit the same command buffer. Although, in this example we wont submit several time, equivalent to use within a context."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d87ac07e505643"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "man = vk.graphics_manager()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d1fc9518896ea1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can clear the render target with dark blue. Images don't need to transition because it will be done internally when necessary. Anyway, image barriers are supported but only to synchronize between two parts of the command buffer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8163a8b1fe0a72d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "man.clear_color(render_target, (0.0, 0.0, 0.4, 1.0))\n",
    "man.clear_depth_stencil(depth_buffer, 1.0, 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcd208cbfda12e0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, lets set the pipeline and the framebuffer. Also, the global descriptor set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ff04d1c6d2285f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "man.set_pipeline(pipeline)\n",
    "man.set_framebuffer(framebuffer)\n",
    "man.bind(global_bindings[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e41c3d028204fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this point the graphics pipeline is setup and the implicit render pass to draw primitives. By default, the pipeline is assuming triangles topology. That can change. The next instruction will dispatch 30 instances of 6 vertices (2 triangles each)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b32070151d68132a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "man.dispatch_primitives(vertices=6, instances=30)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e858b9cdbe6d416"
  },
  {
   "cell_type": "markdown",
   "source": [
    "After populating the command buffer we can use freeze to close the command and prepare for submit."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b236af32a1b6354"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "man.freeze()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74eed33b97516a21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we ask vulky to submit a command buffer. The difference between ```close``` and ```freeze``` is that the inner command buffer if closed gets released automatically to be reused to record again. On the contrary, ```freeze``` will keep it available to re-submit if needed. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba651891829209d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vk.submit(man)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc5686e4e1106414"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we copy the render target to a staging buffer. The difference is that now we require to transition the layout of the render target to the general case (use ANY)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e3a449b520d59e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "staging = vk.tensor(render_target.height, render_target.width, 4) \n",
    "render_target.save(staging)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d21bef622d4894a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(staging.cpu())\n",
    "plt.gca().axis('off')\n",
    "plt.tight_layout(pad=0.0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5818ae8a64f6229"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's prepare a simple animation for this example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d3ec03b529d7d36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "video_data = vk.tensor(100, SCREEN_HEIGHT, SCREEN_WIDTH, 3)  # 100 frames\n",
    "initial_offset = torch.rand(NUMBER_OF_SPRITES, 3)*2 - 1.0\n",
    "initial_offset[..., 2] *= 0.5\n",
    "initial_offset[..., 2] += 0.5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b934b229060ed29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(video_data)):\n",
    "    alpha = i / len(video_data)\n",
    "    # update buffer\n",
    "    # we use inout because we won't change everything, just a field\n",
    "    with sprite_properties.map(mode='inout') as b:  \n",
    "        b.offset = initial_offset\n",
    "        b.offset.y += torch.abs(torch.sin(((initial_offset[...,0] * 100)%1.0)*10 + alpha*30))*0.1\n",
    "        b.offset.x += torch.cos(((initial_offset[...,1]*40)%1.0)*10 + alpha*4)*0.3\n",
    "    # re-submit commands to gpu\n",
    "    with vk.graphics_manager() as b:  # transit from general to render target before rendering\n",
    "        b.use(render_target, vk.ImageUsage.ANY)\n",
    "        b.image_barrier(render_target, vk.ImageUsage.RENDER_TARGET)\n",
    "    vk.submit(man)  # by default will wait until finishes\n",
    "    with vk.graphics_manager() as b:  # transit from render target to general before saving\n",
    "        b.use(render_target, vk.ImageUsage.RENDER_TARGET)\n",
    "        b.image_barrier(render_target, vk.ImageUsage.ANY)\n",
    "    render_target.save(staging)\n",
    "    video_data[i] = staging[...,:3]  # copy current frame to video (only RGB)    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "894ea1a80499a3c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vk.save_video(video_data, 'teaser3.webp', 10, quality=100)\n",
    "import moviepy.editor\n",
    "moviepy.editor.ipython_display(\"teaser3.webp\", filetype='image')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c5007411c5bd95a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
